{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "- Use Langchain to build a chatbot that can answer questions about Harry Potter books\n",
    "- Flexible and customizable RAG pipeline (Retrieval Augmented Generation)\n",
    "- Experiment with various LLMs (Large Language Models)\n",
    "- Use FAISS vector store to store text embeddings created with Sentence Transformers from ðŸ¤—. FAISS runs on GPU and it is much faster than Chroma\n",
    "- Use Retrieval chain to retrieve relevant passages from embedded text\n",
    "- Summarize retrieved passages\n",
    "- Leverage Kaggle dual GPU (2 * T4) with Hugging Face Accelerate\n",
    "- Chat UI with Gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Models\n",
    "- TheBloke/wizardLM-7B-HF\n",
    "- daryl149/llama-2-7b-chat-hf\n",
    "- daryl149/llama-2-13b-chat-hf\n",
    "- mistralai/Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
